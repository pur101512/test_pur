{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-hco1oYcaEH"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# SBERT MODEL TRAINING (NO CLEANING OF THEMES)\n",
        "# ONLY CSAT Score <= 6 FILTER + BASIC STATS + MODEL TRAINING\n",
        "# ===============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 1. Column Names\n",
        "# ---------------------------------------------\n",
        "DESC_COL = \"What are your most important reasons for giving us that score?\"\n",
        "THEME_COL = \"CSAT Theme\"\n",
        "SCORE_COL = \"CSAT score\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 2. Copy Data\n",
        "# ---------------------------------------------\n",
        "df_work = df.copy()\n",
        "df_work[DESC_COL] = df_work[DESC_COL].astype(str)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 3. Theme Column Stats (NO CLEANING)\n",
        "# ---------------------------------------------\n",
        "unique_themes = df_work[THEME_COL].unique()\n",
        "null_themes = df_work[THEME_COL].isna().sum()\n",
        "\n",
        "print(\"\\n========== UNIQUE THEMES (NO CLEANING APPLIED) ==========\")\n",
        "print(unique_themes)\n",
        "print(\"Total unique themes:\", len(unique_themes))\n",
        "\n",
        "print(\"\\n========== NULL THEME COUNT ==========\")\n",
        "print(null_themes)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 4. Filter for CSAT Score <= 6\n",
        "# ---------------------------------------------\n",
        "df_work[SCORE_COL] = pd.to_numeric(df_work[SCORE_COL], errors=\"coerce\")\n",
        "filtered = df_work[df_work[SCORE_COL] <= 6].copy()\n",
        "\n",
        "print(\"\\n========== TOTAL RECORDS WITH CSAT SCORE <= 6 ==========\")\n",
        "print(filtered.shape[0])\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 5. Label Encoding for Themes (NO CLEANING)\n",
        "# ---------------------------------------------\n",
        "label_encoder = LabelEncoder()\n",
        "filtered[\"label\"] = label_encoder.fit_transform(filtered[THEME_COL].astype(str))\n",
        "\n",
        "print(\"\\n========== NUMBER OF CLASSES ==========\")\n",
        "print(len(label_encoder.classes_))\n",
        "print(label_encoder.classes_)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 6. SBERT Embeddings\n",
        "# ---------------------------------------------\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "X_embeddings = model.encode(\n",
        "    filtered[DESC_COL].tolist(),\n",
        "    batch_size=32,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "y = filtered[\"label\"].values\n",
        "\n",
        "print(\"\\nEmbedding shape:\", X_embeddings.shape)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 7. Train Logistic Regression (Multiclass)\n",
        "# ---------------------------------------------\n",
        "clf = LogisticRegression(max_iter=4000, class_weight=\"balanced\")\n",
        "clf.fit(X_embeddings, y)\n",
        "\n",
        "print(\"\\n========== MODEL TRAINING COMPLETED ==========\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SNDCZaQytnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FINAL CSAT ASAT ALL COLUMNS"
      ],
      "metadata": {
        "id": "yqES7vn9ytqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# TRAINING BLOCK — CSAT THEME + ASAT THEME\n",
        "# SCORE <= 6 FOR BOTH MODELS\n",
        "# ===============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# -----------------------------\n",
        "# 1. COLUMN NAMES\n",
        "# -----------------------------\n",
        "CSAT_DESC  = \"What are your most important reasons for giving us that score?\"\n",
        "ASAT_DESC  = \"How could the consultant improve how they handled your enquiry?\"\n",
        "ASAT_GOOD  = \"We’d love to know what the consultant did to earn such a rating?\"\n",
        "\n",
        "CSAT_SCORE = \"CSAT score\"\n",
        "ASAT_SCORE = \"How would you rate the service you received from the consultant handling your enquiry?\"\n",
        "\n",
        "CSAT_THEME = \"CSAT Theme\"\n",
        "ASAT_THEME = \"ASAT Theme\"\n",
        "\n",
        "# -----------------------------\n",
        "# 2. LOAD TRAINING FILE\n",
        "# -----------------------------\n",
        "train_path = r\"training_file.xlsx\"   # <-- change this\n",
        "df = pd.read_excel(train_path)\n",
        "\n",
        "# Convert all text to string\n",
        "df[CSAT_DESC] = df[CSAT_DESC].astype(str)\n",
        "df[ASAT_DESC] = df[ASAT_DESC].astype(str)\n",
        "df[ASAT_GOOD] = df[ASAT_GOOD].astype(str)\n",
        "\n",
        "df[CSAT_SCORE] = pd.to_numeric(df[CSAT_SCORE], errors=\"coerce\")\n",
        "df[ASAT_SCORE] = pd.to_numeric(df[ASAT_SCORE], errors=\"coerce\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3. FILTER SCORE <= 6 (CSAT)\n",
        "# -----------------------------\n",
        "df_csat = df[df[CSAT_SCORE] <= 6].copy()\n",
        "df_csat = df_csat[df_csat[CSAT_DESC].str.strip() != \"\"]\n",
        "\n",
        "print(\"\\n======== UNIQUE CSAT THEMES (<= 6) =========\")\n",
        "print(df_csat[CSAT_THEME].unique())\n",
        "print(\"Total:\", len(df_csat[CSAT_THEME].unique()))\n",
        "\n",
        "# -----------------------------\n",
        "# 4. FILTER SCORE <= 6 (ASAT)\n",
        "# -----------------------------\n",
        "df_asat = df[df[ASAT_SCORE] <= 6].copy()\n",
        "df_asat[\"ASAT_TEXT\"] = (\n",
        "    df_asat[ASAT_GOOD].fillna(\"\") + \" \" +\n",
        "    df_asat[ASAT_DESC].fillna(\"\")\n",
        ").str.strip()\n",
        "df_asat = df_asat[df_asat[\"ASAT_TEXT\"].str.strip() != \"\"]\n",
        "\n",
        "print(\"\\n======== UNIQUE ASAT THEMES (<= 6) =========\")\n",
        "print(df_asat[ASAT_THEME].unique())\n",
        "print(\"Total:\", len(df_asat[ASAT_THEME].unique()))\n",
        "\n",
        "# -----------------------------\n",
        "# 5. LABEL ENCODERS\n",
        "# -----------------------------\n",
        "le_csat = LabelEncoder()\n",
        "df_csat[\"label\"] = le_csat.fit_transform(df_csat[CSAT_THEME].astype(str))\n",
        "\n",
        "le_asat = LabelEncoder()\n",
        "df_asat[\"label\"] = le_asat.fit_transform(df_asat[ASAT_THEME].astype(str))\n",
        "\n",
        "# -----------------------------\n",
        "# 6. SBERT EMBEDDINGS\n",
        "# -----------------------------\n",
        "sbert = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "X_csat = sbert.encode(df_csat[CSAT_DESC].tolist(),\n",
        "                      batch_size=32, show_progress_bar=True)\n",
        "y_csat = df_csat[\"label\"].values\n",
        "\n",
        "X_asat = sbert.encode(df_asat[\"ASAT_TEXT\"].tolist(),\n",
        "                      batch_size=32, show_progress_bar=True)\n",
        "y_asat = df_asat[\"label\"].values\n",
        "\n",
        "# -----------------------------\n",
        "# 7. TRAIN TWO MODELS\n",
        "# -----------------------------\n",
        "clf_csat = LogisticRegression(max_iter=4000, class_weight=\"balanced\")\n",
        "clf_csat.fit(X_csat, y_csat)\n",
        "\n",
        "clf_asat = LogisticRegression(max_iter=4000, class_weight=\"balanced\")\n",
        "clf_asat.fit(X_asat, y_asat)\n",
        "\n",
        "print(\"\\n======== TRAINING COMPLETED FOR BOTH MODELS ========\")\n",
        "\n",
        "# Save these five items externally if needed:\n",
        "# sbert, clf_csat, clf_asat, le_csat, le_asat\n"
      ],
      "metadata": {
        "id": "q9o9Xds5yzW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYHt9QlOyzZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #===============================================================\n",
        "# INFERENCE BLOCK – REPLACE ONLY THEME COLUMN WITH PREDICTIONS\n",
        "# ===============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load New File\n",
        "# -----------------------------\n",
        "input_path = r\"your_file_path_here.xlsx\"   # <-- replace with actual path\n",
        "df_new = pd.read_excel(input_path)\n",
        "\n",
        "DESC_COL = \"What are your most important reasons for giving us that score?\"\n",
        "SCORE_COL = \"CSAT score\"\n",
        "THEME_COL = \"CSAT Theme\"   # this is what we will REPLACE\n",
        "\n",
        "df_new[DESC_COL] = df_new[DESC_COL].astype(str)\n",
        "df_new[SCORE_COL] = pd.to_numeric(df_new[SCORE_COL], errors=\"coerce\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Filter Score <= 6 (Same Logic)\n",
        "# -----------------------------\n",
        "df_infer = df_new[df_new[SCORE_COL] <= 6].copy()\n",
        "df_infer = df_infer[df_infer[DESC_COL].str.strip() != \"\"]\n",
        "\n",
        "print(\"Rows used for inference:\", df_infer.shape[0])\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Convert Text → SBERT Embeddings\n",
        "# -----------------------------\n",
        "X_new = model.encode(\n",
        "    df_infer[DESC_COL].tolist(),\n",
        "    batch_size=32,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Predict Themes\n",
        "# -----------------------------\n",
        "y_new_pred = clf.predict(X_new)\n",
        "predicted_themes = label_encoder.inverse_transform(y_new_pred)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Replace the CSAT Theme Column IN ORIGINAL DATAFRAME\n",
        "# -----------------------------\n",
        "df_new.loc[df_infer.index, THEME_COL] = predicted_themes\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Save Updated File\n",
        "# -----------------------------\n",
        "output_path = \"CSAT_Updated_With_Predicted_Themes.xlsx\"\n",
        "df_new.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"\\nFile saved successfully → {output_path}\")\n",
        "print(\"Only the Theme column was replaced. All other columns remain unchanged.\")\n"
      ],
      "metadata": {
        "id": "g7jmtq-6cfYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7AFcc0qqtrXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ALL_SUBCATEGORY THEME SUBPRODUCT WORKTYPE"
      ],
      "metadata": {
        "id": "YWR7LJnctrfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# FULL PIPELINE — TRAIN + INFERENCE FOR:\n",
        "# SUBCATEGORY, WORK TYPE, SUB-PRODUCT\n",
        "# ===============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 1. COMMON SETUP\n",
        "# ---------------------------------------------------------------\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "DESC1    = \"What are your most important reasons for giving us that score?\"\n",
        "ASAT_POS = \"We’d love to know what the consultant did to earn such a rating?\"\n",
        "ASAT_IMP = \"How could the consultant improve how they handled your enquiry?\"\n",
        "\n",
        "TARGETS = [\"SUBCATEGORY\", \"Work Type\", \"Sub-Product\"]\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 2. TRAINING FUNCTION (Reusable for all 3 models)\n",
        "# ==================================================================\n",
        "def train_text_classifier(df, target_col):\n",
        "\n",
        "    df[\"TEXT_ALL\"] = (\n",
        "        df[DESC1].fillna(\"\") + \" \" +\n",
        "        df[ASAT_POS].fillna(\"\") + \" \" +\n",
        "        df[ASAT_IMP].fillna(\"\")\n",
        "    ).str.strip()\n",
        "\n",
        "    df_train = df.dropna(subset=[\"TEXT_ALL\", target_col]).copy()\n",
        "\n",
        "    # Label encode\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df_train[target_col].astype(str))\n",
        "\n",
        "    # Embeddings\n",
        "    X_emb = model.encode(\n",
        "        df_train[\"TEXT_ALL\"].tolist(),\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Train elasticnet logistic regression\n",
        "    clf = LogisticRegression(\n",
        "        penalty=\"elasticnet\",\n",
        "        solver=\"saga\",\n",
        "        l1_ratio=0.5,\n",
        "        max_iter=600,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    clf.fit(X_emb, y)\n",
        "\n",
        "    print(f\"\\nModel trained for → {target_col}\")\n",
        "    return clf, le\n",
        "\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 3. INFERENCE FUNCTION (Reusable)\n",
        "# ==================================================================\n",
        "def predict_and_update(df_new, clf, le, target_col):\n",
        "\n",
        "    df_new[\"TEXT_ALL\"] = (\n",
        "        df_new[DESC1].fillna(\"\") + \" \" +\n",
        "        df_new[ASAT_POS].fillna(\"\") + \" \" +\n",
        "        df_new[ASAT_IMP].fillna(\"\")\n",
        "    ).str.strip()\n",
        "\n",
        "    df_infer = df_new[df_new[\"TEXT_ALL\"].str.strip() != \"\"].copy()\n",
        "\n",
        "    print(f\"Rows used for inference ({target_col}):\", df_infer.shape[0])\n",
        "\n",
        "    # Encode text\n",
        "    X_new = model.encode(\n",
        "        df_infer[\"TEXT_ALL\"].tolist(),\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    y_pred = clf.predict(X_new)\n",
        "    pred_labels = le.inverse_transform(y_pred)\n",
        "\n",
        "    # Update only that column\n",
        "    df_new.loc[df_infer.index, target_col] = pred_labels\n",
        "\n",
        "    print(f\"{target_col} updated successfully.\")\n",
        "\n",
        "    return df_new\n",
        "\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 4. TRAIN ALL 3 MODELS (SUBCATEGORY, WORK TYPE, SUB-PRODUCT)\n",
        "# ==================================================================\n",
        "train_path = r\"training_file.xlsx\"     # <-- your May–Oct file\n",
        "df_train_all = pd.read_excel(train_path)\n",
        "\n",
        "trained_models = {}   # store models + encoders\n",
        "\n",
        "for tgt in TARGETS:\n",
        "    clf, le = train_text_classifier(df_train_all, tgt)\n",
        "    trained_models[tgt] = (clf, le)\n",
        "\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 5. RUN INFERENCE ON NEW DATA (NOVEMBER FILE)\n",
        "# ==================================================================\n",
        "input_path  = r\"your_november_file.xlsx\"\n",
        "output_path = r\"Updated_All_3_Columns.xlsx\"\n",
        "\n",
        "df_new = pd.read_excel(input_path)\n",
        "\n",
        "# Apply models\n",
        "for tgt in TARGETS:\n",
        "    clf, le = trained_models[tgt]\n",
        "    df_new = predict_and_update(df_new, clf, le, tgt)\n",
        "\n",
        "# Save final updated file\n",
        "df_new.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"ALL 3 COLUMNS UPDATED SUCCESSFULLY:\")\n",
        "print(\" → SUBCATEGORY\")\n",
        "print(\" → WORK TYPE\")\n",
        "print(\" → SUB-PRODUCT\")\n",
        "print(\"File saved as:\", output_path)\n",
        "print(\"===================================================\\n\")\n"
      ],
      "metadata": {
        "id": "jhar4klMtzQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# INFERENCE BLOCK — UPDATE CSAT THEME + ASAT THEME\n",
        "# ONLY SCORE <= 6 ROWS ARE UPDATED\n",
        "# ===============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Make sure these exist from Block 1:\n",
        "# sbert, clf_csat, clf_asat, le_csat, le_asat\n",
        "\n",
        "# -----------------------------\n",
        "# 1. LOAD NEW FILE\n",
        "# -----------------------------\n",
        "input_path = r\"your_new_file.xlsx\"   # <-- change this\n",
        "output_path = r\"Updated_CSAT_ASAT.xlsx\"\n",
        "\n",
        "df_new = pd.read_excel(input_path)\n",
        "\n",
        "df_new[CSAT_DESC] = df_new[CSAT_DESC].astype(str)\n",
        "df_new[ASAT_DESC] = df_new[ASAT_DESC].astype(str)\n",
        "df_new[ASAT_GOOD] = df_new[ASAT_GOOD].astype(str)\n",
        "\n",
        "df_new[CSAT_SCORE] = pd.to_numeric(df_new[CSAT_SCORE], errors=\"coerce\")\n",
        "df_new[ASAT_SCORE] = pd.to_numeric(df_new[ASAT_SCORE], errors=\"coerce\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. CSAT INFERENCE (<= 6)\n",
        "# -----------------------------\n",
        "df_new_csat = df_new[\n",
        "    (df_new[CSAT_SCORE] <= 6) &\n",
        "    (df_new[CSAT_DESC].str.strip() != \"\")\n",
        "].copy()\n",
        "\n",
        "print(\"Rows used for CSAT inference:\", df_new_csat.shape[0])\n",
        "\n",
        "if df_new_csat.shape[0] > 0:\n",
        "    X_new_csat = sbert.encode(\n",
        "        df_new_csat[CSAT_DESC].tolist(),\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "    preds_csat = clf_csat.predict(X_new_csat)\n",
        "    df_new.loc[df_new_csat.index, CSAT_THEME] = le_csat.inverse_transform(preds_csat)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. ASAT INFERENCE (<= 6)\n",
        "# -----------------------------\n",
        "df_new_asat = df_new[\n",
        "    (df_new[ASAT_SCORE] <= 6)\n",
        "].copy()\n",
        "\n",
        "df_new_asat[\"ASAT_TEXT\"] = (\n",
        "    df_new_asat[ASAT_GOOD].fillna(\"\") + \" \" +\n",
        "    df_new_asat[ASAT_DESC].fillna(\"\")\n",
        ").str.strip()\n",
        "\n",
        "df_new_asat = df_new_asat[df_new_asat[\"ASAT_TEXT\"].str.strip() != \"\"]\n",
        "\n",
        "print(\"Rows used for ASAT inference:\", df_new_asat.shape[0])\n",
        "\n",
        "if df_new_asat.shape[0] > 0:\n",
        "    X_new_asat = sbert.encode(\n",
        "        df_new_asat[\"ASAT_TEXT\"].tolist(),\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "    preds_asat = clf_asat.predict(X_new_asat)\n",
        "    df_new.loc[df_new_asat.index, ASAT_THEME] = le_asat.inverse_transform(preds_asat)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. SAVE UPDATED FILE\n",
        "# -----------------------------\n",
        "df_new.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"\\n====================================\")\n",
        "print(\"UPDATED FILE SAVED SUCCESSFULLY:\")\n",
        "print(\" → CSAT Theme (Only score ≤ 6 rows)\")\n",
        "print(\" → ASAT Theme (Only score ≤ 6 rows)\")\n",
        "print(\"Path:\", output_path)\n",
        "print(\"====================================\\n\")\n"
      ],
      "metadata": {
        "id": "EZkLqyQQzDYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SUB CATEGOTY AND OTHER COLUMNS"
      ],
      "metadata": {
        "id": "sstXbUalzJ9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# FINAL PIPELINE — TRAIN + INFERENCE FOR:\n",
        "# SUBCATEGORY, WORK TYPE, SUB-PRODUCT\n",
        "# (Independent of CSAT/ASAT, No Score Filters)\n",
        "# ===============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 1. COMMON SETUP\n",
        "# ---------------------------------------------------------------\n",
        "DESC1    = \"What are your most important reasons for giving us that score?\"\n",
        "ASAT_POS = \"We’d love to know what the consultant did to earn such a rating?\"\n",
        "ASAT_IMP = \"How could the consultant improve how they handled your enquiry?\"\n",
        "\n",
        "TARGETS = [\"SUBCATEGORY\", \"Work Type\", \"Sub-Product\"]\n",
        "\n",
        "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")   # Load once\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 2. TRAINING FUNCTION (Reusable for all 3 models)\n",
        "# ==================================================================\n",
        "def train_text_classifier(df, target_col):\n",
        "\n",
        "    # Build combined text\n",
        "    df[\"TEXT_ALL\"] = (\n",
        "        df[DESC1].fillna(\"\") + \" \" +\n",
        "        df[ASAT_POS].fillna(\"\") + \" \" +\n",
        "        df[ASAT_IMP].fillna(\"\")\n",
        "    ).str.strip()\n",
        "\n",
        "    # Use only rows where target is available\n",
        "    df_train = df.dropna(subset=[\"TEXT_ALL\", target_col]).copy()\n",
        "\n",
        "    # Create label encoder\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df_train[target_col].astype(str))\n",
        "\n",
        "    # SBERT embeddings\n",
        "    X_emb = sbert_model.encode(\n",
        "        df_train[\"TEXT_ALL\"].tolist(),\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Model\n",
        "    clf = LogisticRegression(\n",
        "        penalty=\"elasticnet\",\n",
        "        solver=\"saga\",\n",
        "        l1_ratio=0.5,\n",
        "        max_iter=600,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    clf.fit(X_emb, y)\n",
        "\n",
        "    print(f\"[TRAINED] {target_col}\")\n",
        "\n",
        "    return clf, le\n",
        "\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 3. INFERENCE FUNCTION (Reusable)\n",
        "# ==================================================================\n",
        "def predict_and_update(df_new, clf, le, target_col):\n",
        "\n",
        "    # Build text for inference\n",
        "    df_new[\"TEXT_ALL\"] = (\n",
        "        df_new[DESC1].fillna(\"\") + \" \" +\n",
        "        df_new[ASAT_POS].fillna(\"\") + \" \" +\n",
        "        df_new[ASAT_IMP].fillna(\"\")\n",
        "    ).str.strip()\n",
        "\n",
        "    df_infer = df_new[df_new[\"TEXT_ALL\"].str.strip() != \"\"].copy()\n",
        "\n",
        "    print(f\"Rows used for inference ({target_col}): {df_infer.shape[0]}\")\n",
        "\n",
        "    # Embeddings\n",
        "    X_new = sbert_model.encode(\n",
        "        df_infer[\"TEXT_ALL\"].tolist(),\n",
        "        batch_size=32,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    preds = le.inverse_transform(clf.predict(X_new))\n",
        "\n",
        "    # Ensure column exists --> CREATE if missing\n",
        "    if target_col not in df_new.columns:\n",
        "        df_new[target_col] = None\n",
        "\n",
        "    # Update predictions\n",
        "    df_new.loc[df_infer.index, target_col] = preds\n",
        "\n",
        "    print(f\"[UPDATED] {target_col}\")\n",
        "\n",
        "    return df_new\n",
        "\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 4. TRAIN ALL 3 MODELS (Using Master Training File)\n",
        "# ==================================================================\n",
        "train_path = r\"training_file.xlsx\"       # <-- Your May–Oct training file\n",
        "df_train_all = pd.read_excel(train_path)\n",
        "\n",
        "trained_models = {}\n",
        "\n",
        "for tgt in TARGETS:\n",
        "    clf, le = train_text_classifier(df_train_all, tgt)\n",
        "    trained_models[tgt] = (clf, le)\n",
        "\n",
        "\n",
        "\n",
        "# ==================================================================\n",
        "# 5. INFERENCE ON UPDATED FILE (Generated Earlier by CSAT/ASAT)\n",
        "# ==================================================================\n",
        "updated_csat_asat_file = r\"CSAT_ASAT_Updated.xlsx\"   # <-- Output of previous block\n",
        "final_output_path      = r\"FINAL_All_Columns_Updated.xlsx\"\n",
        "\n",
        "df_final = pd.read_excel(updated_csat_asat_file)\n",
        "\n",
        "# Predict + Update 3 columns\n",
        "for tgt in TARGETS:\n",
        "    clf, le = trained_models[tgt]\n",
        "    df_final = predict_and_update(df_final, clf, le, tgt)\n",
        "\n",
        "# Save final file\n",
        "df_final.to_excel(final_output_path, index=False)\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"FINAL OUTPUT FILE CREATED SUCCESSFULLY\")\n",
        "print(\" → SUBCATEGORY\")\n",
        "print(\" → WORK TYPE\")\n",
        "print(\" → SUB-PRODUCT\")\n",
        "print(\"CSAT + ASAT THEMES already updated earlier.\")\n",
        "print(\"Saved File:\", final_output_path)\n",
        "print(\"===================================================\\n\")\n"
      ],
      "metadata": {
        "id": "DoeIOl63zNo8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}